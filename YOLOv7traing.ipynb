{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Object Detection using YOLOv7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Installing dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "%cd yolov7\n",
    "!pip install -r requirements.txt\n",
    "# !pip install roboflow #roboflow에서 dataset 불러올 경우 설치\n",
    "!apt-get -y install libgl1-mesa-glx\n",
    "!apt-get -y install libglib2.0-0\n",
    "!wget \"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start Training\n",
    "- Note for resuming training from checkpoint\n",
    "\n",
    "By default, the checkpoints for the epoch are stored in folder, yolov7/runs/train, give the relative path to last epoch checkpoints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /workspace/yolov7/\n",
    "!python train.py --batch 64 --cfg cfg/training/yolov7.yaml --epochs 100 --data /workspace/bowling/data/YOLO/data.yaml --weights 'yolov7.pt' --device 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# On image path:\n",
    "%cd /workspace/yolov7/\n",
    "!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.25 --img-size 640 --source /workspace/bowling/data/YOLO/val/images/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Evaluation**\n",
    "- Note the checkpoints from training will be stored by default in runs/train/exp. Take the path of the latest checkpoint\n",
    "\n",
    "We can evaluate the performance of our custom training using the provided evaluation script.\n",
    "After doing below cell, check the inference on folder of test images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(Image(\"/workspace/yolo7/runs/train/exp/F1_curve.png\", width=400, height=400))\n",
    "display(Image(\"/workspace/yolo7/runs/train/exp/PR_curve.png\", width=400, height=400))\n",
    "display(Image(\"/workspace/yolo7/runs/train/exp/confusion_matrix.png\", width=500, height=500))\n",
    "# Run evaluation\n",
    "!python detect.py --weights /workspace/yolov7/runs/train/exp/weights/best.pt --conf 0.1 --source /workspace/yolov7/bowling-1/test/images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference on Video\n",
    "In here, upload video from Local System(maybe Server System..?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_4924/366704768.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# please prepare the video to test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Initializing video object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mvideo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mVideoCapture\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = '/workspace/yolo7/sample_video.mp4'\n",
    "# please prepare the video to test\n",
    "# Initializing video object\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "#Video information\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "nframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialzing object for writing video output\n",
    "output = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'DIVX'),fps , (w,h))\n",
    "torch.cuda.empty_cache()\n",
    "# Initializing model and setting it for inference\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "      classes.append(opt['classes'].index(class_name))\n",
    "\n",
    "  for j in range(nframes):\n",
    "\n",
    "      ret, img0 = video.read()\n",
    "      if ret:\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "          img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment= False)[0]\n",
    "\n",
    "\n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
    "        t2 = time_synchronized()\n",
    "        for i, det in enumerate(pred):\n",
    "          s = ''\n",
    "          s += '%gx%g ' % img.shape[2:]  # print string\n",
    "          gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "          if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "            for c in det[:, -1].unique():\n",
    "              n = (det[:, -1] == c).sum()  # detections per class\n",
    "              s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "              label = f'{names[int(cls)]} {conf:.2f}'\n",
    "              plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        print(f\"{j+1}/{nframes} frames processed\")\n",
    "        output.write(img0)\n",
    "      else:\n",
    "        break\n",
    "\n",
    "\n",
    "output.release()\n",
    "video.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "# Input video path\n",
    "save_path = '/bowling/yolov7/output.mp4'\n",
    "\n",
    "# Compressed video path\n",
    "compressed_path = \"/bowling/result_compressed.mp4\"\n",
    "\n",
    "os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n",
    "\n",
    "# Show video\n",
    "mp4 = open(compressed_path,'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 일단 작성은 다 했는데, 모델 학습시켜서 직접 코드 돌려봐야지 오류나는 부분 잡을 수 있을 것 같다.\n",
    "아니 그리고 패키지 설치 왜안되는건데 ㅡㅡ\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}